# TrapML ğŸ›ï¸ğŸ¶  
**AI-Powered Trap Beat Generator** 

TrapML is a neural beat generation system designed to produce trap-style drum and melody sequences using PyTorch RNNs, audio synthesis, and a dynamic GUI. Built for producers, researchers, and creatives, this tool combines rhythmic neural modeling with real-time audio layering to output unique, high-quality beats from curated samples.

---

## ğŸ”¥ Sample Outputs

This repository includes **three sample `.mp3` files** generated by TrapML using different configuration profiles:

| File          | Description                                           |
|---------------|-----------------------------------------------------|
| `sample1.mp3` | 70 BPM, slowed melody (0.8x), all instruments enabled, flat EQ |
| `sample2.mp3` | 55 BPM, slowed melody (0.5x), no claps or snares, boosted low EQ |
| `sample3.mp3` | 130 BPM, fast melody (1.5x), no claps, boosted high EQ |

These demonstrate the variety of outputs achievable with TrapML by adjusting BPM, melody speed, instrument layers, and EQ settings.

---

## ğŸ¯ Features

- **Neural Pattern Generation:** PyTorch RNNs generate per-instrument rhythmic patterns from seed sequences  
- **Tkinter GUI:** Interactive desktop interface with BPM control, instrument toggles, EQ bands, and melody speed adjustment  
- **Sample Layering Engine:** Combines kick, snare, clap, hi-hat, 808, and melodic loops into synchronized master tracks  
- **Humanization & Swing:** Random off-beat swing adds a natural rhythmic feel  
- **Export Options:** Save generated beats as `.wav` or `.mp3` with built-in compression, EQ, and fades  

---

## ğŸ“ Project Structure

- `trap_core.py` â€” Core backend logic: sample loading, EQ processing, RNN training, beat generation  
- `trap_gui.py` â€” GUI frontend with user controls and export functionality  
- `samples/` â€” Folder containing WAV samples for drums, 808s, and melodies  
- `sample1.mp3`, `sample2.mp3`, `sample3.mp3` â€” Example beats generated with TrapML  

---

## âš™ï¸ Requirements

- Python 3.8 or higher  
- [PyTorch](https://pytorch.org/)  
- [pydub](https://github.com/jiaaro/pydub)  
- [ffmpeg](https://ffmpeg.org/) (installed and in your system PATH)  
- Tkinter (usually pre-installed with Python)  

---

## ğŸ“¦ Installation
```bash
# Clone the repository
git clone https://github.com/Anton9921/TrapML.git

# Navigate to the project directory
cd TrapML

# Install dependencies
pip install torch pydub tkinter
```

## ğŸš€ Usage

Place your our my .wav audio samples into the samples/ folder directory.

Then proceed to run the file:

```bash
python gui.py
```

---

### 5. Use the GUI

- Adjust BPM with the slider (20â€“200 BPM)
- Tune Melody Speed from 0.2x to 2.0x 
- Select which instruments to include: KICK, SNARE, CLAP, HAT, 808
- Adjust EQ Bands (Low, Mid, High) to shape your mix
- Click Generate to build a beat based on current settings
- Click Export to save your beat as a .wav or .mp3 file

### ğŸ§  Architecture Overview

- Lightweight RNN model with sigmoid activations for rhythmic sequence prediction
- Input: binary rhythmic templates per instrument
- Output: refined beat patterns with post-processing for groove and swing
- Audio layering and mastering handled via PyDub, including compression and EQ

---
### ğŸ“œ License

This project is licensed under the MIT License. You are free to use, modify, and distribute this software.
