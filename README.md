# TrapGen ğŸ›ï¸ğŸ¶  
**AI-Powered Trap Beat Generator**

TrapGen is a neural beat generation system designed to produce trap-style drum and melody sequences using PyTorch RNNs, audio synthesis, and a dynamic GUI. Built for producers, researchers, and creative technologists, this tool combines rhythmic neural modeling with real-time audio layering to output unique, high-quality beats from curated samples.

---

## ğŸ”¥ Sample Outputs

This repository includes **three sample `.mp3` files** generated by TrapGen using different configuration profiles:

| File         | Description |
|--------------|-------------|
| `sample1.mp3`   | 70 BPM, default melody speed, all instruments enabled, flat EQ |
| `sample2.mp3`  | 85 BPM, slowed melody (0.6x), no claps or snares, boosted low EQ |
| `sample3.mp3`  | 130 BPM, fast melody (1.5x), no 808s, boosted high EQ |

These demonstrate the variety of outputs achievable with the TrapGen engine by tuning different parameters: BPM, melody speed, instrument layers, and EQ shaping.

---

## ğŸ¯ Features

- âœ… **Neural Pattern Generation**: PyTorch RNNs generate per-instrument rhythms from seed sequences
- âœ… **Tkinter GUI**: Interactive desktop interface with BPM, instrument toggles, EQ, and melody speed control
- âœ… **Sample Layering Engine**: Combines kick, snare, clap, hi-hat, 808, and melodic loops into synchronized master tracks
- âœ… **Humanization & Swing**: Random off-beat swing for more natural rhythm feel
- âœ… **Export to WAV/MP3**: Save beats with built-in post-processing (compression, fade, EQ)

---

## ğŸ“ Project Structure

- `trap_core.py` â€” Core backend logic: sample loading, EQ, RNN training, beat generation
- `trap_gui.py` â€” GUI frontend with user controls and export functionality
- `samples/` â€” Folder with WAV samples for drums, 808s, and melody
- `sample1.mp3`, `sample2.mp3`, `sample3.mp3` â€” Sample beats generated via TrapGen

---

## âš™ï¸ Requirements

- Python 3.8+
- [PyTorch](https://pytorch.org/)
- [pydub](https://github.com/jiaaro/pydub)
- [ffmpeg](https://ffmpeg.org/)
- Tkinter (usually pre-installed)

Install dependencies:
```bash
pip install torch pydub
brew install ffmpeg  # macOS
# or for Windows: download ffmpeg and add to PATH

ğŸš€ How to Use

1. Clone the repository:
git clone https://github.com/yourusername/TrapGen.git
cd TrapGen
2. Prepare your environment:
Ensure you have ffmpeg installed and samples placed in the samples/ folder.

3. Run the app:
python trap_gui.py
4. Use the GUI:
Adjust BPM with the slider (20â€“200 BPM)
Tune melody speed (0.2x to 2.0x) for double time or slowed vibes
Select which instruments to include (KICK, SNARE, CLAP, HAT, 808)
Adjust EQ bands (Low, Mid, High) to sculpt your mix
Click Generate to build a beat
Click Export to save as .wav or .mp3
ğŸ§  Architecture

Model: Lightweight RNN with sigmoid outputs to predict beat sequences
Input: Binary rhythmic templates per instrument
Output: Refined patterns, post-processed for swing and humanization
Audio Layering: Controlled sample alignment using pydub
Mastering: Built-in compression, EQ filtering, and fades
ğŸ§ª Future Ideas

Transformer-based generative backend
MIDI export for DAW use
Real-time generation using asyncio or PyAudio
Web-based frontend (Flask or Streamlit)
Drag-and-drop sample integration
ğŸ“œ License

MIT License. You are free to use, modify, and distribute.
