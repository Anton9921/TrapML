# TrapML 🎛️🎶  
**AI-Powered Trap Beat Generator**

TrapML is a neural beat generation system designed to produce trap-style drum and melody sequences using PyTorch RNNs, audio synthesis, and a dynamic GUI. Built for producers, researchers, and creatives, this tool combines rhythmic neural modeling with real-time audio layering to output unique, high-quality beats from curated samples.

---

## 🔥 Sample Outputs

This repository includes **three sample `.mp3` files** generated by TrapML using different configuration profiles:

| File          | Description                                           |
|---------------|-----------------------------------------------------|
| `sample1.mp3` | 70 BPM, default melody speed, all instruments enabled, flat EQ |
| `sample2.mp3` | 85 BPM, slowed melody (0.6x), no claps or snares, boosted low EQ |
| `sample3.mp3` | 130 BPM, fast melody (1.5x), no 808s, boosted high EQ |

These demonstrate the variety of outputs achievable with TrapML by adjusting BPM, melody speed, instrument layers, and EQ settings.

---

## 🎯 Features

- **Neural Pattern Generation:** PyTorch RNNs generate per-instrument rhythmic patterns from seed sequences  
- **Tkinter GUI:** Interactive desktop interface with BPM control, instrument toggles, EQ bands, and melody speed adjustment  
- **Sample Layering Engine:** Combines kick, snare, clap, hi-hat, 808, and melodic loops into synchronized master tracks  
- **Humanization & Swing:** Random off-beat swing adds a natural rhythmic feel  
- **Export Options:** Save generated beats as `.wav` or `.mp3` with built-in compression, EQ, and fades  

---

## 📁 Project Structure

- `trap_core.py` — Core backend logic: sample loading, EQ processing, RNN training, beat generation  
- `trap_gui.py` — GUI frontend with user controls and export functionality  
- `samples/` — Folder containing WAV samples for drums, 808s, and melodies  
- `sample1.mp3`, `sample2.mp3`, `sample3.mp3` — Example beats generated with TrapML  

---

## ⚙️ Requirements

- Python 3.8 or higher  
- [PyTorch](https://pytorch.org/)  
- [pydub](https://github.com/jiaaro/pydub)  
- [ffmpeg](https://ffmpeg.org/) (installed and in your system PATH)  
- Tkinter (usually pre-installed with Python)  

---

## 🚀 How to Use

### 1. Install Dependencies

pip install torch pydub

Make sure you have ffmpeg installed and accessible in your system PATH:

On macOS:
brew install ffmpeg

On Windows, download from ffmpeg.org and add it to your PATH.

### 2. Clone the Repository

git clone https://github.com/yourusername/TrapML.git
cd TrapML

---

### 3. Prepare Samples

Place your .wav audio samples into the samples/ directory.

### 4. Run the Application

python trap_gui.py

---

### 5. Use the GUI

- Adjust BPM with the slider (20–200 BPM)
- Tune Melody Speed from 0.2x to 2.0x 
- Select which instruments to include: KICK, SNARE, CLAP, HAT, 808
- Adjust EQ Bands (Low, Mid, High) to shape your mix
- Click Generate to build a beat based on current settings
- Click Export to save your beat as a .wav or .mp3 file

### 🧠 Architecture Overview

- Lightweight RNN model with sigmoid activations for rhythmic sequence prediction
- Input: binary rhythmic templates per instrument
- Output: refined beat patterns with post-processing for groove and swing
- Audio layering and mastering handled via PyDub, including compression and EQ

---
### 📜 License

This project is licensed under the MIT License. You are free to use, modify, and distribute this software.
